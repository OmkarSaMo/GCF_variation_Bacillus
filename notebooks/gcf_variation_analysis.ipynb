{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze variation within specific GCFs\n",
    "\n",
    "Here we summarize workflow used to study the variations within particular Gene Cluster Families (GCFs) of plipastatin, fengycin and iturinic lipopetides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data directories used in this analysis\n",
    "\n",
    "    1. ../data/antismash_out : Output folders for all genomes in analysis also used as input for BiGSCAPE software. This is not included in the Github directory, and users can adapt this locally. We use this data only to extract amino acid specificity in this analysis, which part should be adapted accordingly.\n",
    "    2. ../data/bigscape : Output of BiGSCAPE dataset, which will be used to create network and detect families\n",
    "    3. ../data/cytoscape : To save tables to be used by Cytoscape for visualization\n",
    "    4. ../data/bigscape_selected : Rerunning BiGSCAPE for subgroups within specific GCFs to generate CORASSON alignments\n",
    "    5. ../data/frameshift : Nucleotide sequence alignments for selected genes to show conserved frameshift mutations\n",
    "    6. ../tables : Directory to save tables with information on BGCs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from shutil import copyfile\n",
    "from Bio.Align.Applications import MuscleCommandline\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start from the BiGSCAPE output\n",
    "\n",
    "BiG-SCAPE output is stored in '../data/bigscape' directory. Following analysis reads the BiGSCAPE outpur directory and the run labelled as '2020-09-26_08-30-48_hybrids_glocal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dict = dict(bigscape_path = '../data/bigscape/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_path_bigscape(path_dict, run_label):\n",
    "    '''\n",
    "    Update path dictionary with tables from BiG-SCAPE analysis \n",
    "    '''\n",
    "    \n",
    "    networks_dir = os.path.join(path_dict['bigscape_path'], 'network_files')\n",
    "    run_name = [folder for folder in os.listdir(networks_dir) if run_label in folder][0]\n",
    "    path_dict['net_dir'] = os.path.join(networks_dir, run_name)\n",
    "    path_dict['node_table'] = os.path.join(networks_dir, run_name, 'Network_Annotations_Full.tsv')\n",
    "    path_dict['cyto_inputs'] = '../data/cytoscape/input/'\n",
    "    \n",
    "    return path_dict\n",
    "\n",
    "\n",
    "def combine_networks(path_dict, cut_off, run_label):\n",
    "    '''\n",
    "    Combines networks of different classes to generate single network file\n",
    "    '''\n",
    "\n",
    "    net_dir = path_dict['net_dir']\n",
    "    cluster_classes = [cluster_class for cluster_class in os.listdir(net_dir) if not 'Network_Annotations_Full' in cluster_class]\n",
    "\n",
    "    df_network_union = pd.DataFrame()\n",
    "    \n",
    "    for cluster_class in cluster_classes:\n",
    "        class_dir = os.path.join(net_dir, cluster_class)\n",
    "        net_file = cluster_class + '_c' + cut_off + '.network'\n",
    "        \n",
    "        if os.path.isfile(os.path.join(class_dir, net_file)):\n",
    "            df_tmp = pd.read_csv(os.path.join(class_dir, net_file), sep='\\t')\n",
    "            df_network_union = df_network_union.append(df_tmp, ignore_index = True) \n",
    "\n",
    "    cyto_inputs = path_dict['cyto_inputs']\n",
    "    filename = os.path.join(cyto_inputs, run_label + '_network_' + cut_off + '.csv')\n",
    "    df_network_union.to_csv(filename)\n",
    "    \n",
    "    return df_network_union\n",
    "\n",
    "\n",
    "def get_node_table(path_dict, run_label):\n",
    "    '''\n",
    "    Update node annotations for cytoscape\n",
    "    '''\n",
    "    \n",
    "    node_table = path_dict['node_table']\n",
    "    \n",
    "    df_nodes = pd.read_csv(node_table, sep='\\t')\n",
    "    df_nodes.set_index('BGC',inplace=True)\n",
    "   \n",
    "    for bgc in df_nodes.index:\n",
    "        if 'BGC0' in bgc:\n",
    "            mibig_name = df_nodes.loc[bgc, 'Description'].split(' biosynthetic gene cluster')[0]\n",
    "            df_nodes.loc[bgc, 'genome_id'] = mibig_name\n",
    "            df_nodes.loc[bgc, 'genome_src'] = 'MIBIG'\n",
    "            df_nodes.loc[bgc, 'species'] = 'MIBIG'\n",
    "            org = df_nodes.loc[bgc, 'Organism']\n",
    "            if len(org.split(' ')) > 1:\n",
    "                species = org.split(' ')[1]\n",
    "                df_nodes.loc[bgc, 'species'] = species\n",
    "        else:\n",
    "            genome_id = df_nodes.loc[bgc, 'Accesion ID'] \n",
    "            df_nodes.loc[bgc, 'genome_id'] = ''\n",
    "            df_nodes.loc[bgc, 'genome_src'] = 'Public'\n",
    "            org = df_nodes.loc[bgc, 'Organism']\n",
    "            species = org.split(' ')[1]\n",
    "            df_nodes.loc[bgc, 'species'] = species\n",
    "            \n",
    "    cyto_inputs = path_dict['cyto_inputs']\n",
    "    filename = os.path.join(cyto_inputs, run_label + '_nodes.csv')\n",
    "    df_nodes.to_csv(filename)\n",
    "    \n",
    "    return df_nodes\n",
    "    \n",
    "    \n",
    "cut_off = '0.30'\n",
    "run_label = '2020-09-26_08-30-48_hybrids_glocal'\n",
    "\n",
    "path_dict = update_path_bigscape(path_dict, run_label)\n",
    "df_network_union = combine_networks(path_dict, cut_off, run_label)\n",
    "df_nodes = get_node_table(path_dict, run_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use networkx to generate a graph\n",
    "G_clusters = nx.from_pandas_edgelist(df_network_union, 'Clustername 1', 'Clustername 2', 'Raw distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find connected components or BGC families\n",
    "Families_list = list(nx.connected_component_subgraphs(G_clusters))\n",
    "print('Total families detected: ', len(Families_list))\n",
    "\n",
    "# Sort families in decreasing order of size\n",
    "family_size = [len(family) for family in Families_list]\n",
    "orig_index = list(range(len(family_size)))\n",
    "orig_index_fam_size_dict = dict(zip(orig_index, family_size))\n",
    "\n",
    "sorted_index_fam_size_dict = OrderedDict(sorted(orig_index_fam_size_dict.items(), key=lambda x: x[1]), )\n",
    "new_index = list(range(len(family_size)-1,-1,-1))\n",
    "orig_index_sorted = list(sorted_index_fam_size_dict.keys())\n",
    "new_orig_index_dict = dict(zip(new_index, orig_index_sorted))\n",
    "\n",
    "# Ordered family graphs\n",
    "family_graphs = [Families_list[new_orig_index_dict[fam_id]] for fam_id in range(len(Families_list))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of network and Cytoscape and intermediate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The df_network and df_nodes are stored in '../data/cytoscape/input/' directory. These tables are then imported in Cytoscape for visualization of network. Included in Figure S2\n",
    "\n",
    "\n",
    "All the nodes belonging to selected GCFs are then stored in '../tables/df_clusters.csv'. In this study, we isolated BGCs belonging to plipastatin, fengycin GCFs. The classification of these BGCs into subgroups was carried out based on network structure in Cytoscape, which is a manual step. Following steps use this classification from '../tables/df_clusters.csv'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add PATRIC information Geographic location\n",
    "\n",
    "Location information was collected using metadata available at PATRIC database. PATRIC table was downloaded and stored at '../tables/PATRIC_genomes.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patric = pd.read_csv('../tables/PATRIC_genomes.csv', dtype={'Genome ID':str, 'RefSeq Accessions': str}, engine='python')\n",
    "df_clusters = pd.read_csv('../tables/df_clusters.csv', index_col='name')\n",
    "df_patric.set_index('Genome ID', inplace=True)\n",
    "df_patric.fillna('',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbk_dict = dict()\n",
    "refseq_dict = dict()\n",
    "for patric_id in df_patric.index:\n",
    "    gbk_accn = df_patric.loc[patric_id, 'GenBank Accessions']\n",
    "    if ',' in gbk_accn:\n",
    "        gbk_list = gbk_accn.split(',')\n",
    "        for gbk_iter in gbk_list:\n",
    "            if '.' in gbk_iter:\n",
    "                gbk_id = gbk_iter.split('.')[0]\n",
    "            else:\n",
    "                gbk_id = gbk_iter\n",
    "            gbk_dict[gbk_id] = patric_id\n",
    "    else:\n",
    "        if '.' in gbk_accn:\n",
    "            gbk_id = gbk_accn.split('.')[0]\n",
    "        else:\n",
    "            gbk_id = gbk_accn\n",
    "       \n",
    "        gbk_dict[gbk_id] = patric_id\n",
    "    \n",
    "    refseq_accn = df_patric.loc[patric_id, 'RefSeq Accessions']\n",
    "    \n",
    "    if ',' in refseq_accn:\n",
    "        refseq_list = refseq_accn.split(',')\n",
    "        for refseq_iter in refseq_list:\n",
    "            if '.' in refseq_iter:\n",
    "                refseq_id = refseq_iter.split('.')[0]\n",
    "            else:\n",
    "                refseq_id = refseq_iter\n",
    "            refseq_dict[refseq_id] = patric_id\n",
    "    else:\n",
    "        if '.' in refseq_accn:\n",
    "            refseq_id = refseq_accn.split('.')[0]\n",
    "        else:\n",
    "            refseq_id = refseq_accn\n",
    "        refseq_dict[refseq_id] = patric_id\n",
    "    \n",
    "for bgc_id in df_clusters.index:\n",
    "    accn = df_clusters.loc[bgc_id, 'Accesion ID']\n",
    "    if '_' in accn:\n",
    "        if '.' in accn:\n",
    "            gbk_id = accn.split('_')[1].split('.')[0]\n",
    "        else:\n",
    "            gbk_id = accn.split('_')[1]\n",
    "    elif '.' in accn:\n",
    "        gbk_id = accn.split('.')[0]\n",
    "\n",
    "    df_clusters.loc[bgc_id, 'Genbank Accession'] = gbk_id\n",
    "    if gbk_id in gbk_dict.keys():\n",
    "        df_clusters.loc[bgc_id, 'PATRIC'] = gbk_dict[gbk_id]\n",
    "    else:\n",
    "        if accn in refseq_dict.keys():\n",
    "            df_clusters.loc[bgc_id, 'PATRIC'] = refseq_dict[accn]\n",
    "        elif accn[:-2] in refseq_dict.keys():\n",
    "            df_clusters.loc[bgc_id, 'PATRIC'] = refseq_dict[accn[:-2]]\n",
    "        else:\n",
    "            print(accn, df_clusters.loc[bgc_id, 'Organism'])\n",
    "    \n",
    "for bgc_id in df_clusters.index:\n",
    "    patric_id = df_clusters.loc[bgc_id, 'PATRIC']\n",
    "    if patric_id in df_patric.index:\n",
    "        df_clusters.loc[bgc_id, 'Location'] = df_patric.loc[patric_id, 'Geographic Location']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Plipastatin family in details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pps_groups = ['PPS', 'PPS_groupB', 'PPS_groupC', 'PPS_groupD', 'PPS_groupE', 'PPS_others']\n",
    "df_plipastatins = df_clusters[df_clusters.Groups.isin(pps_groups)]\n",
    "df_plipastatins = df_plipastatins.sort_values(by=['Groups', 'Clan Number','Family Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step required all antiSMASH processed data which is not shared on Github.\n",
    "# This step can be adapted as per the local user\n",
    "for node in df_plipastatins.index:\n",
    "    if 'BGC' not in node:\n",
    "        genome_id = df_plipastatins.loc[node, 'Accesion ID']\n",
    "        gbk_path = os.path.join('../data/antismash_out/', genome_id, node + '.gbk')\n",
    "        if not os.path.isfile(gbk_path):\n",
    "            gbk_path = os.path.join('../data/antismash_out/', genome_id.split('.')[0], node + '.gbk')\n",
    "        AA_list = []\n",
    "        with open(gbk_path) as in_handle:\n",
    "            for rec in SeqIO.parse(in_handle, 'genbank'):\n",
    "                for feat in rec.features:\n",
    "                    if feat.type == 'aSDomain':\n",
    "                        if 'specificity' in feat.qualifiers.keys():\n",
    "                            AA_specificity = feat.qualifiers['specificity'][0].split(': ')[1]\n",
    "                            AA_list.append(AA_specificity)\n",
    "        df_plipastatins.loc[node,'AA_domain_list'] = ','.join(AA_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plipastatins = df_plipastatins[['Accesion ID', 'Organism', 'species', 'PATRIC', 'Location', 'Product Prediction', \n",
    "                                   'BiG-SCAPE class', 'Family Number', 'Clan Number', 'Groups', 'AA_domain_list']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plipastatins.to_csv('../tables/df_plipastatins.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze fengycin family in details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fen_groups = ['FEN', 'FEN_groupB', 'FEN_groupC', 'FEN_Others']\n",
    "df_fengycins = df_clusters[df_clusters.Groups.isin(fen_groups)]\n",
    "df_fengycins = df_fengycins.sort_values(by=['Groups', 'Clan Number','Family Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step required all antiSMASH processed data which is not shared on Github.\n",
    "# This step can be adapted as per the local user\n",
    "for node in df_fengycins.index:\n",
    "    if 'BGC' not in node:\n",
    "        genome_id = df_fengycins.loc[node, 'Accesion ID']\n",
    "        gbk_path = os.path.join('../data/antismash_out/', genome_id, node + '.gbk')\n",
    "        if not os.path.isfile(gbk_path):\n",
    "            gbk_path = os.path.join('../data/antismash_out/', genome_id.split('.')[0], node + '.gbk')\n",
    "        AA_list = []\n",
    "        with open(gbk_path) as in_handle:\n",
    "            for rec in SeqIO.parse(in_handle, 'genbank'):\n",
    "                for feat in rec.features:\n",
    "                    if feat.type == 'aSDomain':\n",
    "                        if 'specificity' in feat.qualifiers.keys():\n",
    "                            AA_specificity = feat.qualifiers['specificity'][0].split(': ')[1]\n",
    "                            AA_list.append(AA_specificity)\n",
    "        df_fengycins.loc[node,'AA_domain_list'] = ','.join(AA_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fengycins = df_fengycins[['Accesion ID', 'Organism', 'species', 'PATRIC', 'Location', 'Product Prediction', \n",
    "                                   'BiG-SCAPE class', 'Family Number', 'Clan Number', 'Groups', 'AA_domain_list']]\n",
    "df_fengycins.to_csv('../tables/df_fengycins.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Iturins family in details\n",
    "\n",
    "Apart from Plipastatin and Fengycin GCFs, we further analyzed iturinic lipopeptide GCF in the following section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iturin_myco_bacillo_fam = family_graphs[7] # 8th largest family including iturins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define iturinic AA specificty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iturins = df_nodes.copy()\n",
    "df_iturins = df_iturins.loc[list(iturin_myco_bacillo_fam.nodes), :]\n",
    "\n",
    "iturin_aa = ['ser','asn','pro','gln','asn','tyr','asn']\n",
    "iturin_fw = ','.join(iturin_aa)\n",
    "iturin_bw = ','.join(iturin_aa[::-1])\n",
    "\n",
    "bacillomycinD_aa = ['thr','ser','glu','pro','asn','tyr','asn']\n",
    "bacillomycinD_fw = ','.join(bacillomycinD_aa)\n",
    "bacillomycinD_bw = ','.join(bacillomycinD_aa[::-1])\n",
    "\n",
    "bacillomycinL_aa = ['thr','ser','glu','ser','asn','tyr','asn']\n",
    "bacillomycinL_fw = ','.join(bacillomycinL_aa)\n",
    "bacillomycinL_bw = ','.join(bacillomycinL_aa[::-1])\n",
    "\n",
    "bacillomycinL_aa = ['thr','ser','glu','ser','asn','tyr','asn']\n",
    "bacillomycinL_fw = ','.join(bacillomycinL_aa)\n",
    "bacillomycinL_bw = ','.join(bacillomycinL_aa[::-1])\n",
    "\n",
    "bacillomycinF_aa = ['thr','asn','pro','gln','asn','tyr','asn']\n",
    "bacillomycinF_fw = ','.join(bacillomycinF_aa)\n",
    "bacillomycinF_bw = ','.join(bacillomycinF_aa[::-1])\n",
    "\n",
    "mycosubtilin_aa = ['asn','ser','pro','gln','asn','tyr','asn']\n",
    "mycosubtilin_fw = ','.join(mycosubtilin_aa)\n",
    "mycosubtilin_bw = ','.join(mycosubtilin_aa[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step required all antiSMASH processed data which is not shared on Github.\n",
    "# This step can be adapted as per the local user\n",
    "for node in df_iturins.index:\n",
    "    if 'BGC' not in node:\n",
    "        genome_id = df_iturins.loc[node, 'Accesion ID']\n",
    "        gbk_path = os.path.join('../data/antismash_out/', genome_id, node + '.gbk')\n",
    "        if not os.path.isfile(gbk_path):\n",
    "            gbk_path = os.path.join('../data/antismash_out/', genome_id.split('.')[0], node + '.gbk')\n",
    "        AA_list = []\n",
    "        with open(gbk_path) as in_handle:\n",
    "            for rec in SeqIO.parse(in_handle, 'genbank'):\n",
    "                for feat in rec.features:\n",
    "                    if feat.type == 'aSDomain':\n",
    "                        if 'specificity' in feat.qualifiers.keys():\n",
    "                            AA_specificity = feat.qualifiers['specificity'][0].split(': ')[1]\n",
    "                            AA_list.append(AA_specificity)\n",
    "        AA_str = ','.join(AA_list)\n",
    "        df_iturins.loc[node,'AA_domain_list'] = AA_str\n",
    "        df_iturins.loc[node,'family_number'] = df_nrps_fam_id.loc[node, 'Family Number']\n",
    "        df_iturins.loc[node,'clan_number'] = df_nrps_fam_id.loc[node, 'Clan Number']\n",
    "        \n",
    "        df_iturins.loc[node, 'Groups'] = 'Itu_Others'\n",
    "        \n",
    "        if iturin_fw in AA_str or iturin_bw in AA_str:\n",
    "            df_iturins.loc[node, 'Groups'] = 'Iturin A'\n",
    "           \n",
    "        if bacillomycinD_fw in AA_str or bacillomycinD_bw in AA_str:\n",
    "            df_iturins.loc[node, 'Groups'] = 'Bacillomycin D'\n",
    "            \n",
    "        if bacillomycinL_fw in AA_str or bacillomycinL_bw in AA_str:\n",
    "            df_iturins.loc[node, 'Groups'] = 'Bacillomycin L'\n",
    "            \n",
    "        if bacillomycinF_fw in AA_str or bacillomycinF_bw in AA_str:\n",
    "            df_iturins.loc[node, 'Groups'] = 'Bacillomycin F'\n",
    "            \n",
    "        if mycosubtilin_fw in AA_str or mycosubtilin_bw in AA_str:\n",
    "            df_iturins.loc[node, 'Groups'] = 'Mycosubtilin'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iturins.to_csv('../tables/df_iturins.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update df_clusters with AA specificity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters.loc[df_plipastatins.index, 'AA_domain_list'] = df_plipastatins.AA_domain_list\n",
    "df_clusters.loc[df_fengycins.index, 'AA_domain_list'] = df_fengycins.AA_domain_list\n",
    "\n",
    "for col in df_clusters.columns:\n",
    "    if col in df_iturins.columns:\n",
    "        for bgc_id in df_iturins.index:\n",
    "            df_clusters.loc[bgc_id, col] = df_iturins.loc[bgc_id, col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AA_species = pd.DataFrame(index=df_clusters.Groups.unique(), columns=['AA_domain_list', \n",
    "                    'velezensis', 'amyloliquefaciens', 'subtilis', 'atrophaeus', 'sp.'])\n",
    "\n",
    "df_AA_species[['velezensis', 'amyloliquefaciens', 'subtilis', 'atrophaeus', 'sp.']] = 0\n",
    "for node in df_clusters.index:\n",
    "    if 'BGC0' not in node:\n",
    "        predict_fam = df_clusters.loc[node, 'Groups']\n",
    "        AA_domain_list = df_clusters.loc[node, 'AA_domain_list']\n",
    "        species = df_clusters.loc[node, 'species']\n",
    "\n",
    "        df_AA_species.loc[predict_fam, species] = df_AA_species.loc[predict_fam, species] + 1\n",
    "        df_AA_species.loc[predict_fam, 'AA_domain_list'] = AA_domain_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AA_species # Table S1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate matrix for the Phylogentic tree input \n",
    "\n",
    "Phylogenetic tree and mapping of gene presence absence matrix was carried out as per the https://github.com/KatSteinke/AbsPresTree and included in Figure 2 and Figure S4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accn_list = os.listdir('../data/antismash_out/')\n",
    "col_fams = list(df_clusters.Groups.unique())\n",
    "df_subfam_mat = pd.DataFrame(0, index=accn_list, columns=col_fams)\n",
    "\n",
    "for bgc_id in df_clusters.index:\n",
    "    if 'BGC0' not in bgc_id:\n",
    "        accn_id = df_clusters.loc[bgc_id, 'Accesion ID']\n",
    "        subfam = df_clusters.loc[bgc_id, 'Groups']\n",
    "        df_subfam_mat.loc[accn_id, subfam] = 1\n",
    "        if accn_id not in accn_list:\n",
    "            print(accn_id)\n",
    "\n",
    "df_subfam_mat.fillna(0, inplace=True)\n",
    "df_subfam_mat.sort_index(axis=1, inplace=True)\n",
    "df_subfam_mat.to_csv('../tables/subfam_dist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(df_subfam_mat, cmap='BuPu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze selected clusters separately using cluster alignments\n",
    "\n",
    "BiGSCAPE and CORASSON analysis was repeated separately on individual families of plipastatin and fengycin GCFs, to create Figure S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters = pd.read_csv('../tables/df_clusters.csv', index_col='name')\n",
    "selected_clusters_path = '../data/bigscape_selected/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory with selected clusters\n",
    "groups_selected = ['FEN', 'PPS_groupD', 'PPS_groupE', 'PPS', 'FEN_groupB', 'FEN_groupC', 'PPS_groupC', 'FEN_Others', 'PPS_groupB', 'PPS_others']\n",
    "\n",
    "anti_path = '../data/antismash_out/'\n",
    "for group_name in groups_selected:\n",
    "    df_clusters_group = df_clusters[df_clusters.Groups == group_name]\n",
    "    group_dir = os.path.join(selected_clusters_path, group_name)\n",
    "    if not os.path.isdir(group_dir):\n",
    "        os.mkdir(group_dir)\n",
    "        os.mkdir(os.path.join(group_dir, 'input'))\n",
    "        os.mkdir(os.path.join(group_dir, 'output'))\n",
    "    for cluster_id in df_clusters_group.index:\n",
    "        genome_id = df_clusters_group.loc[cluster_id, 'Accesion ID']\n",
    "        if os.path.isfile(os.path.join(anti_path, genome_id, cluster_id + '.gbk')):\n",
    "            from_path = os.path.join(anti_path, genome_id, cluster_id + '.gbk')\n",
    "            to_path = os.path.join(group_dir, 'input', cluster_id + '.gbk')\n",
    "            copyfile(from_path, to_path)\n",
    "        else:\n",
    "            print(cluster_id, 'not found') \n",
    "    from_path = os.path.join('../data/bigscape_selected/Fengycin.region.gbk')\n",
    "    to_path = os.path.join(group_dir, 'input', 'Fengycin.region.gbk')\n",
    "    copyfile(from_path, to_path)\n",
    "    from_path = os.path.join('../data/bigscape_selected/Plipastatin.region.gbk')\n",
    "    to_path = os.path.join(group_dir, 'input', 'Plipastatin.region.gbk')\n",
    "    copyfile(from_path, to_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run BiGSCAPE on each of the group\n",
    "for group_name in groups_selected:\n",
    "    input_dir = os.path.join(selected_clusters_path, group_name, 'input')\n",
    "    out_dir = os.path.join(selected_clusters_path, group_name, 'output')\n",
    "    bigscape_path = '/home/omkar/Projects/packages/bigscape5/BiG-SCAPE/bigscape.py'\n",
    "    \n",
    "    cmd = 'python ' + bigscape_path + ' -i ' + input_dir + ' -o ' + out_dir + ' --cutoff 0.3 0.5 0.7 --include_singletons'\n",
    "    print(cmd)\n",
    "    os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare genes with frameshifts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1: ppsE gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters = pd.read_csv('../tables/df_clusters.csv', index_col='name')\n",
    "df_selected = df_clusters[df_clusters.Groups == 'PPS_groupE']\n",
    "gbk_path = '../data/bigscape_selected/PPS_groupE/input/'\n",
    "selected_protein_id = 'NP_389712.1'\n",
    "multi_fasta_out = '../data/frameshift/ppsE_groupE.faa'\n",
    "align_out = '../data/frameshift/ppsE_groupE.align'\n",
    "reference_bgc = '../data/bigscape_selected/Plipastatin.region.gbk'\n",
    "reference_gene = 'ppsE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2: fenD gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters = pd.read_csv('../tables/df_clusters.csv', index_col='name')\n",
    "df_selected = df_clusters[df_clusters.Groups == 'FEN_groupB']\n",
    "gbk_path = '../data/bigscape_selected/FEN_groupB/input/'\n",
    "selected_protein_id = 'WP_014305115.1'\n",
    "multi_fasta_out = '../data/frameshift/fenD_groupB.faa'\n",
    "align_out = '../data/frameshift/fenD_groupB.align'\n",
    "reference_bgc = '../data/bigscape_selected/Fengycin.region.gbk'\n",
    "reference_gene = 'fenD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multifasta file\n",
    "selected_sequences = dict()\n",
    "for rec in SeqIO.parse(reference_bgc, 'genbank'):\n",
    "    for feat in rec.features:\n",
    "        if feat.type == 'CDS':\n",
    "            if 'gene' in feat.qualifiers:\n",
    "                gene = feat.qualifiers['gene'][0]\n",
    "                if gene == reference_gene:\n",
    "                    seq_selected = feat.location.extract(rec).seq\n",
    "                    selected_sequences[gene] = seq_selected\n",
    "\n",
    "for bgc_id in df_selected.index:\n",
    "    gbk_in = os.path.join(gbk_path, bgc_id + '.gbk')\n",
    "    print(bgc_id)\n",
    "    for rec in SeqIO.parse(gbk_in, 'genbank'):\n",
    "        for feat in rec.features:\n",
    "            if 'inference' in feat.qualifiers:\n",
    "                inference = feat.qualifiers['inference'][0]\n",
    "                if selected_protein_id in inference:\n",
    "                    locus_tag_selected = feat.qualifiers['locus_tag'][0]\n",
    "                    seq_selected = feat.location.extract(rec).seq\n",
    "                    genome_id = df_clusters.loc[bgc_id, 'Accesion ID']\n",
    "                    locus_tag_selected = genome_id + '_' + locus_tag_selected\n",
    "                    print(locus_tag_selected)\n",
    "                    selected_sequences[locus_tag_selected] = seq_selected\n",
    "            if feat.type == 'CDS':\n",
    "                if 'note' in feat.qualifiers:\n",
    "                    note = feat.qualifiers['note'][0]\n",
    "                    if 'frameshift' in note:\n",
    "                        print(feat.qualifiers['inference'][0])\n",
    "                \n",
    "with open(multi_fasta_out, \"w\") as output_handle:\n",
    "    for locus in selected_sequences.keys():\n",
    "        seq = selected_sequences[locus]\n",
    "        output_handle.write('>%s\\n%s\\n'%(locus, seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align using MUSCLE\n",
    "cline = MuscleCommandline(input=multi_fasta_out, out=align_out)\n",
    "stdout, stderr = cline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
